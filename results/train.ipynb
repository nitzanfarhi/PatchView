{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from transformers import (get_linear_schedule_with_warmup,\n",
    "                          BertConfig, BertForMaskedLM, BertTokenizer,\n",
    "                          GPT2Config, GPT2LMHeadModel, GPT2Tokenizer,\n",
    "                          OpenAIGPTConfig, OpenAIGPTLMHeadModel, OpenAIGPTTokenizer,\n",
    "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                          RobertaConfig, RobertaModel, RobertaTokenizer,\n",
    "                          DistilBertConfig, DistilBertForMaskedLM, DistilBertTokenizer)\n",
    "import json\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import EventsDataset, MyConcatDataset, TextDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from models import get_model\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import copy\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msd import define_activation, get_multi_dataset, get_tokenizer, set_seed\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                        and not args.no_cuda else \"cpu\")\n",
    "args.n_gpu = torch.cuda.device_count()\n",
    "\n",
    "args.device = device\n",
    "if args.n_gpu == 0:\n",
    "    args.n_gpu = 1\n",
    "\n",
    "args.eval_batch_size = args.batch_size\n",
    "args.train_batch_size = args.batch_size\n",
    "\n",
    "args.per_gpu_train_batch_size = args.batch_size//args.n_gpu\n",
    "args.per_gpu_eval_batch_size = args.batch_size//args.n_gpu\n",
    "# Setup logging\n",
    "logger.warning(f\"Device: {device}, n_gpu: {args.n_gpu}\")\n",
    "\n",
    "# Set seed\n",
    "set_seed(args.seed)\n",
    "\n",
    "args.start_epoch = 0\n",
    "args.start_step = 0\n",
    "\n",
    "if args.cache_dir:\n",
    "    args.model_cache_dir = os.path.join(args.cache_dir, \"models\")\n",
    "\n",
    "logger.warning(\"Training/evaluation parameters %s\", args)\n",
    "\n",
    "args.code_activation = define_activation(args.code_activation)\n",
    "args.message_activation = define_activation(args.message_activation)\n",
    "args.event_activation = define_activation(args.event_activation)\n",
    "\n",
    "\n",
    "with open(os.path.join(args.cache_dir, \"orc\", \"orchestrator.json\"), \"r\") as f:\n",
    "    mall = json.load(f)\n",
    "\n",
    "code_tokenizer, message_tokenizer = None, None\n",
    "    \n",
    "if args.source_model == \"Code\":\n",
    "    code_tokenizer = get_tokenizer(\n",
    "        args, args.code_model_type, args.code_tokenizer_name)\n",
    "    dataset = TextDataset(code_tokenizer, args, mall,\n",
    "                            mall.keys(), args.code_embedding_type, balance=False)\n",
    "    code_tokenizer = dataset.tokenizer\n",
    "    args.return_class = True\n",
    "    dataset = MyConcatDataset(args, code_dataset=dataset)\n",
    "\n",
    "\n",
    "elif args.source_model == \"Message\":\n",
    "    message_tokenizer = get_tokenizer(\n",
    "        args, args.message_model_type, args.message_tokenizer_name)\n",
    "    dataset = TextDataset(message_tokenizer, args, mall,\n",
    "                            mall.keys(), args.message_embedding_type, balance=False)\n",
    "    args.return_class = True\n",
    "    dataset = MyConcatDataset(args, message_dataset=dataset)\n",
    "\n",
    "\n",
    "elif args.source_model == \"Events\":\n",
    "    dataset = EventsDataset(args, mall, mall.keys(),  balance=True)\n",
    "    args.xshape1 = dataset[0][0].shape[0]\n",
    "    args.xshape2 = dataset[0][0].shape[1]\n",
    "    args.return_class = True\n",
    "    dataset = MyConcatDataset(args, events_dataset=dataset)\n",
    "\n",
    "elif args.source_model == \"Multi\":\n",
    "    dataset, code_tokenizer, message_tokenizer = get_multi_dataset(args, mall)\n",
    "    args.return_class = True\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_acc = 0\n",
    "splits = KFold(n_splits=args.folds, shuffle=True, random_state=args.seed)\n",
    "\n",
    "best_accs = []\n",
    "mall_keys_list = np.array(list(mall.keys()))\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(mall_keys_list)))):\n",
    "    if args.run_fold != -1 and args.run_fold != fold:\n",
    "        continue\n",
    "\n",
    "    logger.warning('Running Fold {}'.format(fold))\n",
    "    dataset.set_hashes(mall_keys_list[train_idx], is_train=True)\n",
    "    dataset.set_hashes(mall_keys_list[val_idx], is_train=False)\n",
    "\n",
    "    with wandb.init(project=\"MSD4\", tags=[args.source_model],  config=args) as run:\n",
    "        model = get_model(args, message_tokenizer=message_tokenizer, code_tokenizer=code_tokenizer)\n",
    "        run.define_metric(\"epoch\")\n",
    "\n",
    "        best_acc = train(args, dataset, model, fold,\n",
    "                            train_idx, run, eval_idx=val_idx)\n",
    "        best_accs.append(best_acc)\n",
    "        test(args, model, dataset, val_idx, fold=fold)\n",
    "        run.summary[f\"best_acc\"]  = max(best_accs)\n",
    "\n",
    "\n",
    "        model_dir = os.path.join(args.output_dir, '{}'.format('checkpoint-best-acc'))\n",
    "        output_dir = os.path.join(model_dir, f'{args.source_model}_model_{fold}.bin')\n",
    "        artifact = wandb.Artifact(f'{args.source_model}_model_{fold}.bin', type='model')\n",
    "        artifact.add_file(output_dir)\n",
    "        run.log_artifact(artifact)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
